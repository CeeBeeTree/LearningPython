{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KTH Actions Data Set (Video files) - Loading and Classification\n",
    "**Author:** Christian Byron  **Date:** 30-Jun-21\n",
    "\n",
    "This notebook provides an example of loading and classifying the KTH Action dataset in its original form (avi video). This is the second clssification activity for this dataset and as such will focus on a reduced dataset with only three of the original  six actions (walk, jog, run). These actions have low accuracy in the prior classification experiement due to similarity of viewing them as static images.\n",
    "\n",
    "### Step 1 - Define a dataset class to view and load the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os import listdir, path\n",
    "import random \n",
    "\n",
    "class KTHA2_dataset:\n",
    "\n",
    "        def __init__(self):\n",
    "            self.__base_video_path =  \"C:\\\\Users\\\\s441606\\\\Documents\\\\Videos\\\\KTHA\"\n",
    "            self.__data = []\n",
    "            \n",
    "            label_dirs = [ d  for d in listdir(self.__base_video_path) if \n",
    "                          not(path.isfile(path.join(self.__base_video_path, f)))]\n",
    "            \n",
    "            for d in label_dirs:\n",
    "                for f in listdir(path.join(self.__base_video_path, d)):\n",
    "                    self.__data.append( (f, d) )\n",
    "                    \n",
    "            self.__small_sample_data = random.sample(self.__data, 10)\n",
    "            \n",
    "        def video_list(self): \n",
    "            # Get a random sample of 10\n",
    "            return [f[0] for f in self.__small_sample_data]\n",
    "\n",
    "        def video_annotations(self, video_ref):\n",
    "            return []\n",
    "        \n",
    "        def video_annotation_frame_num(self,video_ref, annotation_ref):\n",
    "            pass\n",
    "        \n",
    "        def video_end_frame_num(self, video_ref):\n",
    "            pass\n",
    "        \n",
    "        def video_start_frame_num(self, video_ref):\n",
    "            pass\n",
    "        \n",
    "        def video_frame(self, video_ref, frame_num):\n",
    "            pass\n",
    "                                    \n",
    "        def video_annotated_frame(self, video_ref, annotation_ref, frame_num):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
