{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Reconstruction for Collective Activity Dataset (CAD-2)\n",
    "**Author:** Christian Byron  **Date:** 19-Apr-21\n",
    "\n",
    "This notebook provides an understanding of the Collective Activity dataset by reconstructing it into a video gui. \n",
    "\n",
    "The Collective Activity Dataset (available [here](http://vhosts.eecs.umich.edu/vision//activity-dataset.html)) was created by <sub>[1]</sub> \n",
    "\n",
    "- [ ] get the markup corrected to put the annotation description into a table \n",
    "\n",
    "\n",
    "- The original dataset contains 5 different collective activities : crossing, walking, waiting, talking, and queueing and 44 short video sequences some of which were recorded by consumer hand-held digital camera with varying view point.\n",
    "- The augmented dataset (used here) added two more categories (dancing and jogging)\n",
    "\n",
    "#### Annotation\n",
    "\n",
    "Every 10th frame in all video sequences was annotated with image location of person, activity id, and pose direction.\n",
    "\n",
    "Frame number, X, Y, WIDTH, HEIGHT, CLASS ID, POSE ID.\n",
    "ex. 001       366     168     106     212     5       3\n",
    "    001     512     190     98      195     5       3\n",
    "    001     440     187     84      167     5       3\n",
    "    001     339     191     83      165     5       3\n",
    "\n",
    "CLASS ID \n",
    "1. NA, 2. Crossing, 3. Waiting, 4.Queuing, 5. Walking (not use), 6. Talking, 7. Dancing, 8. Jogging\n",
    "\n",
    "POSE ID\n",
    "1. Right 2. Front-right 3. Front 4. Front-left 5. Left 6. Back-left 7. Back 8. Back-right\n",
    "\n",
    "\n",
    "### Step 1 - Find all videos and individual frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "class CAD_dataset:\n",
    "        def __init__(self):\n",
    "            self.__base_video_collection_path = \"C:\\\\Users\\\\s441606\\\\Documents\\\\Videos\\\\CAD\"\n",
    "            \n",
    "          \n",
    "            \n",
    "        def video_list(self): \n",
    "            return os.listdir(self.__base_video_collection_path)\n",
    "        \n",
    "        def video_annotations(self, video_ref):\n",
    "            return []\n",
    "        \n",
    "        def video_annotation_frame_num(self,video_ref, annotation_ref):\n",
    "            pass\n",
    "        \n",
    "        def video_end_frame_num(self, video_ref):\n",
    "            path = self.__base_video_collection_path + \"//\" + video_ref\n",
    "            video_files = [f for f in os.listdir(path) if f.endswith('.jpg')]\n",
    "            return int(video_files[-1][-7:-4])\n",
    "        \n",
    "        def video_start_frame_num(self, video_ref):\n",
    "            path = self.__base_video_collection_path + \"//\" + video_ref\n",
    "            video_files = [f for f in os.listdir(path) if f.endswith('.jpg')]\n",
    "            return int(video_files[0][-7:-4])\n",
    "        \n",
    "        def video_frame(self, video_ref, frame_num):\n",
    "            path = self.__base_video_collection_path + \"//\" + video_ref\n",
    "            filename = f\"frame{frame_num:04d}.jpg\"\n",
    "            \n",
    "            file = open(path + \"//\" + filename ,\"rb\")\n",
    "            return file.read()\n",
    "                                    \n",
    "        def video_annotated_frame(self, video_ref, annotation_ref, frame_num):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Build the GUI Function to show video frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745faf2272704870b6c964acb783f4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Video #:', options=('seq45',), value='seq45'), Play(value=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from VideoDatasetUI import VideoDatasetUI\n",
    "\n",
    "ds = CAD_dataset()\n",
    "videoUI = VideoDatasetUI(ds)\n",
    "videoUI.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lessons Learnt\n",
    "- \n",
    "\n",
    "#### References\n",
    "[1] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
